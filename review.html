<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Heuristic Detail – Critical Design Strategy</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<header class="header">
  <div class="container">
    <h1>Critical Design Strategy (CDS)</h1>
    <p class="tagline">A structured method for evaluating visualisation designs</p>
  </div>
  <nav class="nav">
    <div class="container">
      <ul class="nav-list">
 <li><a href="index.html">Home</a></li>
        <li><a href="highlights.html">Highlights</a></li>
        <li><a href="overview.html">Overview</a></li>
        <li><a href="detail.html" >Detail</a></li>
        <li><a href="review.html" class="active">Review</a></li>
        <li><a href="reading.html">Further Reading</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </div>
  </nav>
</header>

  <section class="intro-section">
    <div class="container">
      <h2>Scoring System</h2>
      <p>
        Each heuristic question is rated on a <strong>Likert scale from -2 to +2</strong>, reflecting how well the artefact meets the given criterion.

      </p>
      <ul>
        <li><strong>+2 – Excellent:</strong> Strongly satisfies the heuristic.</li>
        <li><strong>+1 – Good:</strong> Mostly satisfies it, with minor concerns.</li>
        <li><strong>0 – Neutral:</strong> Neither good nor bad; unclear or inconsistent.</li>
        <li><strong>-1 – Weak:</strong> Shows issues; could be improved.</li>
        <li><strong>-2 – Poor:</strong> Strongly fails to meet the heuristic.</li>
      </ul>
      <p>
        Instructors or self-appraisers may choose to annotate each score with brief reasoning or link it to visual or interface evidence.
      </p>
    </div>
  </section>

  <section class="intro-section">
    <div class="container">
      <h2>Understanding the Score: Looking Beyond the Numbers</h2>

<p>  Each heuristic question is rated on a <strong>Likert scale from -2 to +2</strong>, representing how well the artefact meets each specific criterion. However, these numbers are not meant to be used as a simple aggregate or final judgment. While it's good  to calculate an average or total score, this can actually obscure the complexity of the critique. So the overall score must be considered in its entirity and how it has been created. For example, strong performance in one area may hide weaknesses in another—averaging would flatten these differences.
</p>
<p>
Treat the scores as signposts for reflection. They help surface patterns, highlight standout areas (positive or negative), and guide thoughtful interpretation. Used alongside the qualitative insights you’ve gathered—such as your chosen title, the essence summary, and your observations across the six perspectives—the ratings become much more powerful.
</p>
</div>
</section>



  <section class="intro-section">
    <div class="container">
      <h2>Reviewing and Aggregating Scores</h2>
      <p>
        After all 30 heuristics have been considered, scores can be averaged or grouped by perspective (e.g., Interface vs. Design). This gives both a quantitative and qualitative picture of strengths and weaknesses.
      </p>
      <p>
        Common use cases include:
      </p>
      <ul>
        <li><strong>Identifying weak areas</strong> that need redesign or testing</li>
        <li><strong>Documenting improvement</strong> over time or iterations</li>
        <li><strong>Discussing trade-offs</strong> between conflicting design goals</li>
      </ul>
    </div>
  </section>

    <section class="intro-section">
    <div class="container">
      <h2>Moving Into Review: From Insight to Action</h2>
      <p>
        The goal of the final stage is to distil the key findings and translate them into meaningful, actionable steps for improving the design or artefact. Begin by reviewing the overall critique—your ratings, notes, and observations. Pay special attention to any perspectives that stand out, either due to consistently high or low scores.
      </p>
      <p>
Next, assess the strengths and weaknesses. Where did the design succeed? Where did it fall short? These reflections should lead naturally into identifying concrete areas for improvement. Then, define your next steps. This might include:      </p>
      <ul>
      <li>  Prototyping new ideas based on identified issues</li>
  <li>Refining layouts or visual elements</li>
<li>Enhancing usability</li>
<li>Responding to user feedback</li>
<li>Conducting further research or usability testing</li>
</ul>

<br>
<p>Finally, establish clear goals for the redesign process, and consider how progress will be measured. Whether you’re iterating on a small aspect or rethinking the design more broadly, the Review stage should close the loop, so ensuring that critique leads to change.</p>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <p>&copy; 2025 Critical Design Strategy (CDS). Created by the CDS Authors. All rights reserved.</p>
    </div>
  </footer>
</body>
</html>
